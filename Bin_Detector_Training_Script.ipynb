{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import bias\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.measure import label, regionprops\n",
    "import copy\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder  = 'data_scraping/data/'\n",
    "\n",
    "_, _, color_data_files = next(os.walk(folder))\n",
    "color_data_files.remove('.DS_Store')\n",
    "color_data_files = sorted(color_data_files,key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "# Load the first file first to initialize an array\n",
    "with open(folder + color_data_files[0]) as file_name:\n",
    "\n",
    "    # Initialize color data\n",
    "    color_data = np.loadtxt(file_name, delimiter=\",\")\n",
    "\n",
    "# Load the rest of the data\n",
    "for ID, filename in enumerate(color_data_files):\n",
    "\n",
    "    # Skip the first file since it is loaded\n",
    "    if ID == 0:\n",
    "\n",
    "        continue\n",
    "        \n",
    "    if ID == 6:\n",
    "        break\n",
    "\n",
    "    # Training images (Number of Pixels x Number of Features)\n",
    "    with open(folder + filename) as file_name:\n",
    "        \n",
    "        new_data = np.loadtxt(file_name, delimiter=\",\")\n",
    "\n",
    "    color_data = np.vstack((color_data, new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.  48. 183. ...  94. 203.   1.]\n",
      " [  0.  44. 191. ...  94. 209.   1.]\n",
      " [  0.  43. 190. ...  94. 209.   1.]\n",
      " ...\n",
      " [130. 163. 196. ... 109. 150.  15.]\n",
      " [130. 163. 196. ... 109. 150.  15.]\n",
      " [131. 164. 197. ... 109. 150.  15.]]\n"
     ]
    }
   ],
   "source": [
    "# Sort the color label in an ascending order\n",
    "idc = np.argsort(color_data[:, -1]) \n",
    "sorted_color_data = color_data[idc]\n",
    "print(sorted_color_data[:-10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 10514, 12.0: 6493, 14.0: 3266, 15.0: 17778}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data counts for each color class\n",
    "unique, counts = np.unique(sorted_color_data[:,-1], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6274, 13)\n"
     ]
    }
   ],
   "source": [
    "# Unique pixel only\n",
    "compressed_color_data = [tuple(row) for row in sorted_color_data]\n",
    "compressed_color_data = np.unique(compressed_color_data, axis=0)\n",
    "print(compressed_color_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 1248, 12.0: 3522, 14.0: 508, 15.0: 996}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data counts for each color class\n",
    "unique, counts = np.unique(compressed_color_data[:,-1], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.  73. 214. ...  83. 210.   1.]\n",
      " [  4.  66. 211. ...  85. 211.   1.]\n",
      " [  4.  66. 209. ...  85. 210.   1.]\n",
      " ...\n",
      " [ 98. 133. 173. ... 107. 154.  15.]\n",
      " [117. 147. 183. ... 110. 151.  15.]\n",
      " [123. 154. 185. ... 110. 149.  15.]]\n"
     ]
    }
   ],
   "source": [
    "# Re-sort the array\n",
    "idc = np.argsort(compressed_color_data[:, -1]) \n",
    "sorted_compressed_color_data = compressed_color_data[idc]\n",
    "print(sorted_compressed_color_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_train and y_train\n",
    "X_train = sorted_color_data[:, :-1]\n",
    "y_train = sorted_color_data[:,-1]\n",
    "\n",
    "### X_test\n",
    "folder = \"bin_detection/data/validation\"\n",
    "#folder = \"bin_detection/data/training\"\n",
    "filename = '0067.jpg'\n",
    "img = cv2.imread(os.path.join(folder,filename))\n",
    "img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "img_LAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "img_RGB_norm = img_RGB.astype(np.float64)/255\n",
    "img_HSV_norm = img_HSV.astype(np.float64)/255\n",
    "img_LAB_norm = img_LAB.astype(np.float64)/255\n",
    "img_YCrCb_norm = img_YCrCb.astype(np.float64)/255\n",
    "\n",
    "img_height, img_width, _ = img.shape\n",
    "\n",
    "# Initialize a mask\n",
    "mask_img = np.zeros((img_height,img_width), np.uint8) # Black Pixel = 0, White Pixel = 1\n",
    "\n",
    "# Reshape the image from H x W x 3 to (H X W) X 3\n",
    "img_RGB_norm = img_RGB_norm.reshape(img_RGB_norm.shape[0]*img_RGB_norm.shape[1],img_RGB_norm.shape[2])\n",
    "img_HSV_norm = img_HSV_norm.reshape(img_HSV_norm.shape[0]*img_HSV_norm.shape[1],img_HSV_norm.shape[2])\n",
    "img_LAB_norm = img_LAB_norm.reshape(img_LAB_norm.shape[0]*img_LAB_norm.shape[1],img_LAB_norm.shape[2])\n",
    "img_YCrCb_norm = img_YCrCb_norm.reshape(img_YCrCb_norm.shape[0]*img_YCrCb_norm.shape[1],img_YCrCb_norm.shape[2])\n",
    "\n",
    "# Compile the dataset as X_test (N x 12 features)\n",
    "X_test = np.concatenate((img_RGB_norm, img_HSV_norm, img_LAB_norm, img_YCrCb_norm), axis = 1)\n",
    "#X_test = img_RGB_norm\n",
    "#X_test = np.concatenate((img_RGB_norm, img_HSV_norm), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1328338, 12) (38051, 12) (38051,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n",
      "/Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ -0.0356813 ,  -9.22751274,  -6.75686698,   7.78064151,\n",
      "        -0.11059022,   6.49368513,   5.43087308,  -4.39806456,\n",
      "         0.60314113, -12.09164392,  -5.84650138,  -6.99441   ,\n",
      "         3.11712916]), array([ 3.84581535e-03,  2.63773987e+00,  5.77359467e+00, -1.00396181e+01,\n",
      "       -4.59486166e+00,  4.49659603e+00, -2.13225103e+00,  3.95830549e+00,\n",
      "       -4.96569968e+00,  8.50421667e+00,  3.02654883e+00,  2.09753997e-01,\n",
      "       -6.89575385e+00]), array([ 0.01010631,  1.12571405, -2.59338792, -0.17900986,  3.32512964,\n",
      "       -5.37405822, -2.85897579, -2.21201353,  2.76821721,  0.17751123,\n",
      "       -1.18360195,  2.97470124,  1.88253437]), array([ -0.03832304,   9.30501004,  -0.68463526,  17.95919346,\n",
      "        22.64897308,  -1.10390407, -12.75129632,  -4.25016015,\n",
      "       -17.64312805, -18.30170296,   4.34483157,  -1.39027227,\n",
      "         2.89745888])]\n"
     ]
    }
   ],
   "source": [
    "def one_VS_ALL_LogReg(X_train, y_train, X, lr = 0.1, max_iters = 5000, err_tol = 1e-3, bias = 1):\n",
    "    \n",
    "    # Define sigmoid function\n",
    "    def sigmoid(func_x):\n",
    "        return 1 / (1 + np.exp(-func_x))\n",
    "\n",
    "    # Add bias term\n",
    "    X_train = np.insert(X_train, 0, bias, axis = 1)\n",
    "\n",
    "    # Train\n",
    "    # Number of samples and features\n",
    "    num_Samples, num_Features = X_train.shape\n",
    "\n",
    "    # List that stores the weights\n",
    "    weights = []\n",
    "\n",
    "    # Array that stores every iteration of loss\n",
    "    loss_arry = np.zeros(max_iters)\n",
    "    \n",
    "    # Different Color Classes\n",
    "    color_class = np.unique(y_train)\n",
    "\n",
    "    # One vs ALL Binary Classification\n",
    "    for color in color_class:\n",
    "\n",
    "        # Binary label whether is the current color or not. (1 is the color, 0 is not)\n",
    "        binary_label = np.where(y_train == color, 1, 0)\n",
    "\n",
    "        # Initialize the weight\n",
    "        weight = np.zeros(num_Features)\n",
    "\n",
    "        for idx in range(0, max_iters):\n",
    "\n",
    "            # Determine Probability\n",
    "            y_predicted = sigmoid(np.dot(X_train, weight))\n",
    "\n",
    "            # Cross Entropy Loss function\n",
    "            loss_arry[idx] = 1 / num_Samples * np.sum(-binary_label * np.log(y_predicted) * np.log(1 - y_predicted))\n",
    "\n",
    "            # Gradient Descend function\n",
    "            grad_desc = 1 / num_Samples * (np.dot((binary_label - y_predicted), X_train))\n",
    "\n",
    "            # Store previous weight\n",
    "            prev_weight = copy.deepcopy(weight)\n",
    "\n",
    "            # Update weight\n",
    "            weight += lr * grad_desc\n",
    "\n",
    "            # If less than the error tolerance, break the loop to prevent overtraining/overfitting (early stopping)\n",
    "            if np.linalg.norm(prev_weight - weight) < err_tol:\n",
    "                break\n",
    "\n",
    "        # Append the trained weight\n",
    "        weights.append(weight)\n",
    "        \n",
    "    print(weights)\n",
    "\n",
    "    # Add bias term\n",
    "    X_test = np.insert(X, 0, bias, axis = 1)\n",
    "\n",
    "    # Predicted label\n",
    "    y_predicted = [np.argmax([sigmoid(np.dot(x_test, weight)) for weight in weights]) for x_test in X_test]\n",
    "\n",
    "    # Predict the outcome\n",
    "    y = np.rint(np.array([color_class[color] for color in y_predicted]))\n",
    "    \n",
    "    return y\n",
    "\n",
    "print(X_test.shape, X_train.shape, y_train.shape)\n",
    "\n",
    "y_predict = one_VS_ALL_LogReg(X_train, y_train, X_test, lr = 0.1, max_iters = 5000, err_tol = 1e-3, bias = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQLklEQVR4nO3dfcyV9X3H8fd33IBVhoBWg0AGWuI0a30YqVCXppHWpxlxiU1szGQdC8nmNlu3VJxJk/03N1OdyaIl0oZ2rLWjbhLjRqwPfyyxrNgqPiDlrnZyF+tDVHyaCvrdH+d34xFu+J0b7nOuc9j7ldw51/X7/a5zfc8v5/5wPZxzE5mJJOnAfqPpAiSp3xmUklRhUEpShUEpSRUGpSRVGJSSVNGVoIyICyNiW0QMR8SqbuxDknolJvpzlBExCfg58AVgBPgJ8KXMfGpCdyRJPdKNI8pPA8OZ+Uxmvgd8H1jWhf1IUk8MdeE55wA72tZHgHP2HRQRK4GVAJOY9LtHM70LpUhSZ97g1Zcz8+Nj9XUjKGOMtv3O7zNzNbAaYHrMynNiaRdKkaTO/CjX/8+B+rpx6j0CzGtbnwvs7MJ+JKknuhGUPwEWRsSCiJgCXAFs6MJ+JKknJvzUOzP3RMSfAxuBScC3MvPJid6PJPVKN65Rkpn3Avd247klqdf8Zo4kVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUkU1KCNiXkQ8GBFbI+LJiLimtM+KiPsiYnt5nFnaIyJujYjhiNgSEWd3+0VIUjd1ckS5B/irzDwNWAxcHRGnA6uA+zNzIXB/WQe4CFhYflYCt0141ZLUQ9WgzMznM/OnZfkNYCswB1gGrC3D1gKXleVlwHey5cfAjIiYPeGVS1KPjOsaZUTMB84CNgEnZubz0ApT4IQybA6wo22zkdK273OtjIjNEbF5N++Ov3JJ6pGOgzIipgE/BL6Sma8fbOgYbblfQ+bqzFyUmYsmM7XTMiSp5zoKyoiYTCsk12XmXaX5hdFT6vL4YmkfAea1bT4X2Dkx5UpS73Vy1zuANcDWzPxGW9cGYHlZXg7c3dZ+Vbn7vRjYNXqKLkmDaKiDMecCfwg8HhGPlra/Af4O+EFErACeA75Y+u4FLgaGgbeBL09oxZLUY9WgzMz/YuzrjgBLxxifwNWHWZck9Q2/mSNJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJU0ckf7pUG2n25fu/yYxzfk32+zWTWcRrbYlZP9qfuMijVmFqAfWrJm2Nut+XhaYe8zzN4+ZC3PRRf59ye7k/dYVCqL4wZYA8faOw7h7yfxzj+gAF8uEYD/BR2MY3dHM3uruxHvWdQqi+M54hyvD54+F0mkbzJEH8dn2PjXY/WNzoEnwQuOOlMbsqHen7kqu4yKNWYxzieM3iZXHIUn7xrxn79yf5th+J/Z/+SaezhmOnvs3Fbd0JSRzbvektShUEpTaCNOz1iPRIZlNIE69bNIjXHoJSkCoNSkioMSh3xjpn+ftMlaMAZlGrc4XzTRuoFg1J94YKTzmy6BOmADEr1DcNS/cpv5qgvHEmfP9zy8LTD+j66+o9HlJJUYVCqcZ1+QNtTczXFoNTAOJJOzzVYDEpJqug4KCNiUkT8LCLuKesLImJTRGyPiDsjYkppn1rWh0v//O6ULo3PW69P8vRdh2Q8R5TXAFvb1m8Ebs7MhcCrwIrSvgJ4NTM/AdxcxkkH1M8fODdYBR0GZUTMBX4fuKOsB3AeMPqfnqwFLivLy8o6pX9pGS8NHK+LCjo/orwF+BrwQVk/DngtM/eU9RFgTlmeA+wAKP27ynjpiOcR6JGpGpQRcQnwYmY+0t48xtDsoK/9eVdGxOaI2LybdzsqVpKa0Mk3c84FLo2Ii4GjgOm0jjBnRMRQOWqcC+ws40eAecBIRAwBxwKv7PukmbkaWA0wPWbtF6SS1C+qR5SZeX1mzs3M+cAVwAOZeSXwIHB5GbYcuLssbyjrlP4HMtMglDSwDudzlNcB10bEMK1rkGtK+xrguNJ+LbDq8EqUpGaN649iZOZDwENl+Rng02OMeQf44gTUJkl9wW/mSFKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUGpvnDBSWf6J8rUtwxKSaowKKUJ4hHxkcuglKQKg1JHvLden9R0CRpwBqUkVRiUklRhUEpShUGpvjLRd469E62JMK7/CkLqhlPYxU350N71x2d3tt2nlrx5wL4tD08D4CYe4mO8/5G+9vDcuPPRzgs9AMP4yGdQqjFvMxmAaezmDF4e/xM8fOCuM3hnv7ajeP8jgQydh/LB3MRHn/MUdh3+k6qvGJRqzDpOA+Bodnd1P/N5nWN5jyHy0AL5EI3+Q6DBZ1CqMdtiFl/n3K7v59R8hSvZ2vVAbvc2k/nn8g+BBp9BqSNerwJZRy7vektShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklTRUVBGxIyIWB8RT0fE1ohYEhGzIuK+iNheHmeWsRERt0bEcERsiYizu/sSJKm7Oj2i/EfgPzPzt4EzgK3AKuD+zFwI3F/WAS4CFpaflcBtE1qxJPVYNSgjYjrwWWANQGa+l5mvAcuAtWXYWuCysrwM+E62/BiYERET8HekJakZnRxRngy8BHw7In4WEXdExDHAiZn5PEB5PKGMnwPsaNt+pLR9RESsjIjNEbF5N+8e1ouQpG7qJCiHgLOB2zLzLOAtPjzNHkuM0Zb7NWSuzsxFmbloMlM7KlaSmtBJUI4AI5m5qayvpxWcL4yeUpfHF9vGz2vbfi6wc2LKlaTeqwZlZv4a2BERp5ampcBTwAZgeWlbDtxdljcAV5W734uBXaOn6JI0iDr9P3P+AlgXEVOAZ4Av0wrZH0TECuA54Itl7L3AxcAw8HYZK0kDq6OgzMxHgUVjdC0dY2wCVx9mXZLUN/xmjiRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpSRUdBGRFfjYgnI+KJiPheRBwVEQsiYlNEbI+IOyNiShk7tawPl/753XwBktRt1aCMiDnAXwKLMvN3gEnAFcCNwM2ZuRB4FVhRNlkBvJqZnwBuLuMkaWB1euo9BHwsIoaAo4HngfOA9aV/LXBZWV5W1in9SyMiJqZcSeq9alBm5q+Am4DnaAXkLuAR4LXM3FOGjQBzyvIcYEfZdk8Zf9y+zxsRKyNic0Rs3s27h/s6JKlrOjn1nknrKHEBcBJwDHDRGENzdJOD9H3YkLk6Mxdl5qLJTO28YknqsU5OvT8PPJuZL2XmbuAu4DPAjHIqDjAX2FmWR4B5AKX/WOCVCa1aknqok6B8DlgcEUeXa41LgaeAB4HLy5jlwN1leUNZp/Q/kJn7HVFK0qDo5BrlJlo3ZX4KPF62WQ1cB1wbEcO0rkGuKZusAY4r7dcCq7pQtyT1TPTDwd70mJXnxNKmy5D0/9iPcv0jmblorD6/mSNJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFQalJFUYlJJUYVBKUoVBKUkVBqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVGFQSlKFQSlJFZGZTddARLwBbGu6jnE4Hni56SI6NEi1wmDVO0i1gvXW/FZmfnysjqEeFnEw2zJzUdNFdCoiNg9KvYNUKwxWvYNUK1jv4fDUW5IqDEpJquiXoFzddAHjNEj1DlKtMFj1DlKtYL2HrC9u5khSP+uXI0pJ6lsGpSRVNB6UEXFhRGyLiOGIWNUH9cyLiAcjYmtEPBkR15T2WRFxX0RsL48zS3tExK2l/i0RcXYDNU+KiJ9FxD1lfUFEbCq13hkRU0r71LI+XPrnN1DrjIhYHxFPlzle0udz+9XyPngiIr4XEUf10/xGxLci4sWIeKKtbdzzGRHLy/jtEbG8h7X+Q3kvbImIf4uIGW1915dat0XEBW3tvc+MzGzsB5gE/AI4GZgCPAac3nBNs4Gzy/JvAj8HTgf+HlhV2lcBN5bli4H/AAJYDGxqoOZrgX8B7inrPwCuKMu3A39alv8MuL0sXwHc2UCta4E/KctTgBn9OrfAHOBZ4GNt8/pH/TS/wGeBs4En2trGNZ/ALOCZ8jizLM/sUa3nA0Nl+ca2Wk8veTAVWFByYlJTmdHTX5IxJm4JsLFt/Xrg+iZrGqPGu4Ev0Prm0OzSNpvWh+QBvgl8qW383nE9qm8ucD9wHnBP+SV4ue3Nt3eOgY3AkrI8VMZFD2udXoIn9mnv17mdA+woATJU5veCfptfYP4+4TOu+QS+BHyzrf0j47pZ6z59fwCsK8sfyYLRuW0qM5o+9R59I44aKW19oZw6nQVsAk7MzOcByuMJZVjTr+EW4GvAB2X9OOC1zNwzRj17ay39u8r4XjkZeAn4drlUcEdEHEOfzm1m/gq4CXgOeJ7WfD1C/87vqPHOZ9Pv4VF/TOuIF/qs1qaDMsZo64vPK0XENOCHwFcy8/WDDR2jrSevISIuAV7MzEc6rKfp+R6idep1W2aeBbxF69TwQBqtt1zbW0br1O8k4BjgooPU1PT81hyovsbrjogbgD3AutGmMYY1VmvTQTkCzGtbnwvsbKiWvSJiMq2QXJeZd5XmFyJidumfDbxY2pt8DecCl0bEL4Hv0zr9vgWYERGj3+Nvr2dvraX/WOCVHtU6uv+RzNxU1tfTCs5+nFuAzwPPZuZLmbkbuAv4DP07v6PGO5+NznO5eXQJcGWW8+mD1NRIrU0H5U+AheUu4hRaF8A3NFlQRASwBtiamd9o69oAjN4NXE7r2uVo+1XljuJiYNfoaU+3Zeb1mTk3M+fTmrsHMvNK4EHg8gPUOvoaLi/je3bkkJm/BnZExKmlaSnwFH04t8VzwOKIOLq8L0br7cv5bTPe+dwInB8RM8tR9Pmlresi4kLgOuDSzHx7n9dwRfkkwQJgIfDfNJUZ3b4I2sHF3Ytp3Vn+BXBDH9Tze7QO5bcAj5afi2lda7of2F4eZ5XxAfxTqf9xYFFDdX+OD+96n0zrTTUM/CswtbQfVdaHS//JDdR5JrC5zO+/07rL2rdzC/wt8DTwBPBdWndh+2Z+ge/Run66m9bR1opDmU9a1weHy8+Xe1jrMK1rjqO/a7e3jb+h1LoNuKitveeZ4VcYJami6VNvSep7BqUkVRiUklRhUEpShUEpSRUGpSRVGJSSVPF/Mv60laHZsK0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the image dimension\n",
    "img_height, img_width, _ = img.shape\n",
    "\n",
    "# Initialize a mask\n",
    "mask_img = np.zeros((img_height,img_width), np.uint8) # Black Pixel = 0, White Pixel = 1\n",
    "\n",
    "y_predict_2D = y_predict.reshape(img_height, img_width) # Height x Width\n",
    "\n",
    "# Unmask the pixel that is a recycling-bin-blue\n",
    "for height in range(img_height):\n",
    "    for width in range(img_width):\n",
    "        if y_predict_2D[height, width] == 1:\n",
    "            mask_img[height, width] = 1 # Recycling-Blue-Bin is a white pixel\n",
    "\n",
    "fig = plt.figure() \n",
    "            \n",
    "kernel_errosion_shape = 3\n",
    "kernel_dilation_shape = 8\n",
    "kernel_errosion = np.ones((kernel_errosion_shape, kernel_errosion_shape), np.uint8)\n",
    "kernel_dilation = np.ones((kernel_dilation_shape, kernel_dilation_shape), np.uint8)\n",
    "\n",
    "# Erode to filter out noise\n",
    "mask_img = cv2.erode(mask_img, kernel_errosion, iterations = 3)\n",
    "# Dilate to regain the size of the recycle bin without noise\n",
    "mask_img = cv2.dilate(mask_img, kernel_dilation, iterations = 2)\n",
    "\n",
    "# Labeled array, where all connected regions are assigned the same integer value.\n",
    "label_img = label(mask_img)\n",
    "\n",
    "# Return  list of RegionProperties from the label_img\n",
    "regions = regionprops(label_img)\n",
    "\n",
    "# Initialize the box list\n",
    "boxes = []\n",
    "\n",
    "# Regions props\n",
    "for props in regions:\n",
    "\n",
    "    # Make sure the the size of the recycling bin blue is appropriate[0.55, 0.008]\n",
    "    if  0.55 * mask_img.shape[0] * mask_img.shape[1] > props.area > 0.006 * mask_img.shape[0] * mask_img.shape[1]:\n",
    "\n",
    "        # Get the bounding box top left and bottom right coordinates\n",
    "        minr, minc, maxr, maxc = props.bbox\n",
    "\n",
    "        # Calculate the height and width of the bounding box\n",
    "        bb_height, bb_width = maxr - minr, maxc - minc\n",
    "\n",
    "        # Check if the hight-to-width ratio of the recycling-bin-blue makes sense. [1.0, 2.55]\n",
    "        if bb_width * 1.0 < bb_height < bb_width * 2.55:\n",
    "\n",
    "            # X-coordinates\n",
    "            bx = (minc, maxc, maxc, minc, minc)\n",
    "            # Y-coordinates\n",
    "            by = (minr, minr, maxr, maxr, minr)\n",
    "            # Draw bounding box\n",
    "                  \n",
    "            plt.plot(bx, by, '-r', linewidth=2.5)\n",
    "            # Add to boxes list\n",
    "            boxes.append([minc, minr, maxc, maxr])\n",
    "            \n",
    "plt.imshow(mask_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38051, 13)\n"
     ]
    }
   ],
   "source": [
    "print(sorted_color_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.  48. 183. ...  94. 203.   1.]\n",
      " [  0.  44. 191. ...  94. 209.   1.]\n",
      " [  0.  43. 190. ...  94. 209.   1.]\n",
      " ...\n",
      " [128. 161. 196. ... 109. 151.  15.]\n",
      " [130. 163. 196. ... 109. 150.  15.]\n",
      " [100. 138. 177. ... 106. 154.  15.]]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_color_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
